# -*- coding: utf-8 -*-
"""soil2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Eqp-fXOnKK5aIQUpBhO_1em-5e0-AgG4

INSTALLING THE REQUIRED MODELS
"""

!pip install tensorflow scikit-learn pandas numpy

"""IMPORTING THE REQUIRED LIBRARIES"""

import os
import numpy as np
import pandas as pd
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input
from tensorflow.keras.models import Model

"""MOUNTING THE GOOGLE DRIVE AND ACCESSING THE DATASET"""

# BASE_DIR = "soil_competition-2025"
# TRAIN_DIR = os.path.join(BASE_DIR, "train")
# TEST_DIR = os.path.join(BASE_DIR, "test")
# TRAIN_CSV = os.path.join(BASE_DIR, "train_labels.csv")
# TEST_CSV = os.path.join(BASE_DIR, "test_ids.csv")
# SUBMISSION_PATH = os.path.join(BASE_DIR, "submission.csv")

# IMG_SIZE = 224
from google.colab import drive
drive.mount('/content/drive')
import os

# Replace with your actual path if different
base_path = "/content/drive/MyDrive/soil_competition-2025"

TRAIN_CSV = os.path.join(base_path, "train_labels.csv")
TEST_CSV = os.path.join(base_path, "test_ids.csv")
TRAIN_DIR = os.path.join(base_path, "train")
TEST_DIR = os.path.join(base_path, "test")

"""LOADING THE DATA"""

def load_images(image_list, folder):
    images = []
    valid_ids = []
    for img_name in image_list:
        path = os.path.join(folder, img_name)
        try:
            image = load_img(path, target_size=(IMG_SIZE, IMG_SIZE))
            image = img_to_array(image)
            image = preprocess_input(image)
            images.append(image)
            valid_ids.append(img_name)
        except Exception as e:
            print(f"Error loading {path}: {e}")
    return np.array(images), valid_ids

"""LOADING CSV"""

train_df = pd.read_csv(TRAIN_CSV)
test_df = pd.read_csv(TEST_CSV)
print(train_df)
print(test_df)

"""LOADING IMAGES"""

train_images, valid_train_ids = load_images(train_df['image_id'], TRAIN_DIR)
test_images, valid_test_ids = load_images(test_df['image_id'], TEST_DIR)

"""EXTRACTING FEATURES"""

print("ðŸ“¦ Extracting features using InceptionV3...")
base_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))
model = Model(inputs=base_model.input, outputs=base_model.output)

train_features = model.predict(train_images, verbose=1)
test_features = model.predict(test_images, verbose=1)

"""SCALING THE FEATURES"""

scaler = StandardScaler()
train_scaled = scaler.fit_transform(train_features)
test_scaled = scaler.transform(test_features)

"""ONE-CLASS SVM"""

svm = OneClassSVM(kernel='rbf', gamma='auto', nu=0.1)  # nu ~ fraction of outliers
svm.fit(train_scaled)
# Predict: +1 = soil, -1 = not soil
preds = svm.predict(test_scaled)
pred_labels = np.where(preds == 1, 1, 0)  # 1: soil, 0: not soil

"""SAVING THE FINAL ANSWER"""

SUBMISSION_PATH = os.path.join(base_path, "submission.csv")
os.makedirs(os.path.dirname(SUBMISSION_PATH), exist_ok=True)

output_df.to_csv(SUBMISSION_PATH, index=False)
print(f"âœ… Created submission.csv at {SUBMISSION_PATH}")
